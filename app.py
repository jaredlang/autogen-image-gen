from dotenv import load_dotenv

import requests 
from datetime import datetime 
from os import environ

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
import autogen

import replicate

load_dotenv()

OUTPUT_FOLDER = environ["OUTPUT_FOLDER"]
REPLICATE_API_TOKEN = environ["REPLICATE_API_TOKEN"]

autogen_config_list = config_list_from_json(
    env_or_file="OAI_CONFIG_LIST",
    # filter_dict={
    #     # Function calling with GPT 3.5
    #     "model": ["gpt-3.5-turbo"],
    # }
)

# Create llm config for group chat manager 
# - GroupChatManager is not allowed to make function/tool calls.
autogen_llm_config = {
    "config_list": autogen_config_list
}

# Create llm config for assistants
autogen_llm_config_assistant = {
    "functions": [
        {
            "name": "text_to_image_generation",
            "description": "use latest AI model to generate image based on a prompt, return the file path of image generated",
            "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {
                            "type": "string",
                            "description": "a great text to image prompt that describe the image",
                        }
                    },
                "required": ["prompt"],
            },
        },
        {
            "name": "image_review",
            "description": "review & critique the AI generated image based on original prompt, decide how can images & prompt can be improved",
            "parameters": {
                    "type": "object",
                    "properties": {
                        "prompt": {
                            "type": "string",
                            "description": "the original prompt used to generate the image",
                        },
                        "image_file_path": {
                            "type": "string",
                            "description": "the image file path, make sure including the full file path & file extension",
                        }
                    },
                "required": ["prompt", "image_file_path"],
            },
        },
    ],
    "config_list": autogen_config_list,
}

# function to use stability-ai model to generate image
def text_to_image_generation(prompt: str) -> str:
    output = replicate.run(
        "stability-ai/sdxl:c221b2b8ef527988fb59bf24a8b97c4561f1c671f73bd389f866bfb27c061316",
        input={
            "prompt": prompt
        }
    )

    if output and len(output) > 0:
        # Get the image URL from the output
        image_url = output[0]
        print(f"generated image for {prompt}: {image_url}")

        # Download the image and save it with a filename based on the prompt and current time
        current_time = datetime.now().strftime("%Y%m%d%H%M%S")
        shortened_prompt = prompt[:50]
        image_file_path = f"{OUTPUT_FOLDER}/{shortened_prompt}_{current_time}.png"

        response = requests.get(image_url)
        if response.status_code == 200:
            with open(image_file_path, "wb") as file:
                file.write(response.content)
            print(f"Image saved as '{image_file_path}'")
            return image_file_path
        else:
            raise Exception("Failed to download and save the image.")
    else:
        raise Exception("Failed to generate the image.")


def img_review(image_file_path: str, prompt: str):
    output = replicate.run(
        "yorickvp/llava-13b:6bc1c7bb0d2a34e413301fee8f7cc728d2d4e75bfab186aa995f63292bda92fc",
        input={
            "image": open(image_file_path, "rb"),
            "prompt": f"What is happening in the image? From scale 1 to 10, decide how similar the image is to the text prompt {prompt}?",
        }
    )

    result = ""
    for item in output:
        result += item

    print("CRITIC : ", result)

    return result


# Create assistant agent
img_gen_assistant = AssistantAgent(
    name="text_to_img_prompt_expert",
    system_message="You are a text to image AI model expert, you will use text_to_image_generation function to generate image with prompt provided, and also improve prompt based on feedback provided until it is 10/10.",
    llm_config=autogen_llm_config_assistant,
    function_map={
        "text_to_image_generation": text_to_image_generation
    }
)

img_critic_assistant = AssistantAgent(
    name="img_critic",
    system_message="You are an AI image critique, you will use img_review function to review the image generated by the text_to_img_prompt_expert against the original prompt, and provide feedback on how to improve the prompt.",
    llm_config=autogen_llm_config_assistant,
    function_map={
        "image_review": img_review
    }
)

# Create user proxy agent
user_proxy = UserProxyAgent(
    name="user_proxy",
    human_input_mode="ALWAYS",
)

# user_proxy = UserProxyAgent(
#     name="user_proxy",
#     human_input_mode="TERMINATE",
#     max_consecutive_auto_reply=10,
#     is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
#     code_execution_config={
#         "work_dir": "web",
#         "use_docker": False,
#     },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.
#     llm_config=autogen_llm_config,
#     system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
# Otherwise, reply CONTINUE, or the reason why the task is not solved yet.""",
# )

# Create groupchat
groupchat = autogen.GroupChat(
    agents=[user_proxy, img_gen_assistant, img_critic_assistant], messages=[], max_round=50,)

manager = autogen.GroupChatManager(
    groupchat=groupchat,
    llm_config=autogen_llm_config)

message = "A realistic image of a cute rabbit wearing sunglasses confidently driving a shiny red sports car on a sunny day with a scenic road in the background."
# message = "In Houston at 2pm, Sunny sky with few clouds. Current Temperature at 37"

# text_to_image_generation(message)

# img_review('./output/A realistic image of a cute rabbit wearing sunglas_20240218135543.png', message)

# # Start the conversation
user_proxy.initiate_chat(
    manager, message=message)
